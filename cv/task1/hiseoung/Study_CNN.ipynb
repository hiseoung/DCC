{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Study_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CSMOF4Yh-h7",
        "outputId": "39686d23-1f6a-4636-d7f2-abf3a706b4e3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RETTi3K0ebeS",
        "outputId": "b82f9ff6-5da1-4bc9-b4c3-582e3dfe4e9b"
      },
      "source": [
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bldQ2Qxuey-v"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko1ZxEx4fGJJ",
        "outputId": "eb2c82ba-9f9a-4f03-e041-5b013b78d474"
      },
      "source": [
        "# GPU 사용 여부 체크\n",
        "if torch.cuda.is_available():\n",
        "  DEVICE = torch.device('cuda')\n",
        "else:\n",
        "  DEVICE = torch.device('cpu')\n",
        "\n",
        "print(DEVICE)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us6-Dx7cfiHs"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 5"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTvKKkPbiZ1V"
      },
      "source": [
        "path = '/content/drive/MyDrive/data/ComputerVision'"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhnBC2-Af3xW"
      },
      "source": [
        "# MNIST Train 데이터 받아오기\n",
        "train_dataset = datasets.MNIST(root=path, train = True, download = True, transform = transforms.ToTensor())\n",
        "# MNIST Test 데이터 받아오기\n",
        "test_dataset = datasets.MNIST(root=path, train = False, download = True, transform = transforms.ToTensor())"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNc0gAdliiwt"
      },
      "source": [
        "# 받아온 MNIST데이터를 batch_size로 분리해서 변환\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size= batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size= batch_size, shuffle=True)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqGUiLKpj1U1",
        "outputId": "56640241-3349-4d10-8a1a-df5733581528"
      },
      "source": [
        "for x, y in train_loader:\n",
        "  print('변환 후 데이터 Shape : ', x.size())\n",
        "  print('레이블 데이터 수 : ', y.size())\n",
        "  break"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "변환 후 데이터 Shape :  torch.Size([32, 1, 28, 28])\n",
            "레이블 데이터 수 :  torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOU9VYXbks9K"
      },
      "source": [
        "# CNN 모델 정의\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    # Convolution Layer \n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_channels = 1,\n",
        "        out_channels = 8,\n",
        "        kernel_size = 3,\n",
        "        padding = 1\n",
        "    )\n",
        "\n",
        "    # Convolution Layer \n",
        "    self.conv2 = nn.Conv2d(\n",
        "        in_channels = 8,\n",
        "        out_channels = 16,\n",
        "        kernel_size = 3,\n",
        "        padding = 1\n",
        "    )\n",
        "\n",
        "    # Pooling Layer\n",
        "    self.pool = nn.MaxPool2d(\n",
        "        kernel_size = 2\n",
        "    )\n",
        "\n",
        "    # MLP 적용 후 Classification(0 ~ 9(10개)중 출력)\n",
        "    self.fc1 = nn.Linear(28 * 28, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 32)\n",
        "    self.fc4 = nn.Linear(32, 10)\n",
        "    \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    # Flatten\n",
        "    x = x.view(-1, 28 * 28)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc4(x)\n",
        "    x = F.log_softmax(x)\n",
        "    return x"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1NBxSgotrPK",
        "outputId": "436475c7-e317-4d39-994a-e23df8894081"
      },
      "source": [
        "model = CNN().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc4): Linear(in_features=32, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6UpYKohsDlA"
      },
      "source": [
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(image), \n",
        "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
        "                loss.item()))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji0ZeC3dtm3p"
      },
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            prediction = output.max(1, keepdim = True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "    \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJGYbcrebX_D",
        "outputId": "3e16196e-707a-4b9e-8009-60600f23b3be"
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, train_loader, optimizer, log_interval = 200)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, test_loss, test_accuracy))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tTrain Loss: 2.300843\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tTrain Loss: 0.411210\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tTrain Loss: 0.110800\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tTrain Loss: 0.305054\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tTrain Loss: 0.078446\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tTrain Loss: 0.170565\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tTrain Loss: 0.236088\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tTrain Loss: 0.138760\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tTrain Loss: 0.212492\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tTrain Loss: 0.010111\n",
            "\n",
            "[EPOCH: 1], \tTest Loss: 0.0024, \tTest Accuracy: 97.56 % \n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tTrain Loss: 0.013687\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tTrain Loss: 0.151592\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tTrain Loss: 0.098539\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tTrain Loss: 0.074938\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tTrain Loss: 0.012479\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tTrain Loss: 0.189503\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tTrain Loss: 0.333624\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tTrain Loss: 0.001581\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tTrain Loss: 0.116016\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tTrain Loss: 0.070462\n",
            "\n",
            "[EPOCH: 2], \tTest Loss: 0.0014, \tTest Accuracy: 98.53 % \n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tTrain Loss: 0.004946\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tTrain Loss: 0.017126\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tTrain Loss: 0.015981\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tTrain Loss: 0.009011\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tTrain Loss: 0.023733\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tTrain Loss: 0.041740\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tTrain Loss: 0.040180\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tTrain Loss: 0.002606\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tTrain Loss: 0.016288\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tTrain Loss: 0.001235\n",
            "\n",
            "[EPOCH: 3], \tTest Loss: 0.0014, \tTest Accuracy: 98.56 % \n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tTrain Loss: 0.026722\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tTrain Loss: 0.014018\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tTrain Loss: 0.011712\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tTrain Loss: 0.000708\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tTrain Loss: 0.101791\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tTrain Loss: 0.020961\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tTrain Loss: 0.004033\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tTrain Loss: 0.033459\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tTrain Loss: 0.182901\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tTrain Loss: 0.004648\n",
            "\n",
            "[EPOCH: 4], \tTest Loss: 0.0011, \tTest Accuracy: 98.82 % \n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tTrain Loss: 0.022573\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tTrain Loss: 0.004633\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tTrain Loss: 0.028077\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tTrain Loss: 0.003215\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tTrain Loss: 0.039457\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tTrain Loss: 0.002961\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tTrain Loss: 0.002294\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tTrain Loss: 0.000961\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tTrain Loss: 0.002212\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tTrain Loss: 0.094009\n",
            "\n",
            "[EPOCH: 5], \tTest Loss: 0.0014, \tTest Accuracy: 98.60 % \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}